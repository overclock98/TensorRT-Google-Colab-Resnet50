{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorRT_Resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLelIdNJocl4JuEoLqiVPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overclock98/TensorRT-Google-Colab-Resnet50/blob/main/TensorRT_Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n55tyCEz9xVD",
        "outputId": "104ce4e7-a4c3-4185-bb6a-cce8138d0c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: nvidia-pyindex in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: nvidia-tensorrt in /usr/local/lib/python3.7/dist-packages (8.4.3.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu11 in /usr/local/lib/python3.7/dist-packages (from nvidia-tensorrt) (2022.4.8)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11 in /usr/local/lib/python3.7/dist-packages (from nvidia-tensorrt) (2022.4.25)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11 in /usr/local/lib/python3.7/dist-packages (from nvidia-tensorrt) (2022.5.19)\n",
            "Requirement already satisfied: nvidia-cublas-cu117 in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11->nvidia-tensorrt) (11.10.1.25)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu117->nvidia-cublas-cu11->nvidia-tensorrt) (57.4.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu117 in /usr/local/lib/python3.7/dist-packages (from nvidia-cuda-runtime-cu11->nvidia-tensorrt) (11.7.60)\n",
            "Requirement already satisfied: nvidia-cudnn-cu116 in /usr/local/lib/python3.7/dist-packages (from nvidia-cudnn-cu11->nvidia-tensorrt) (8.4.0.27)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: pycuda<2021.1 in /usr/local/lib/python3.7/dist-packages (2020.1)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pycuda<2021.1) (4.4.2)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda<2021.1) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda<2021.1) (2022.1.12)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda<2021.1) (1.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda<2021.1) (2.5.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda<2021.1) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda<2021.1) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda<2021.1) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda<2021.1) (3.8.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install nvidia-pyindex\n",
        "!pip3 install nvidia-tensorrt\n",
        "!pip3 install onnx\n",
        "!python3 -m pip install 'pycuda<2021.1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://learnopencv.com/wp-content/uploads/2020/06/turkish_coffee.jpg -O \"turkish_coffee.jpg\"\n",
        "!wget https://files.worldwildlife.org/wwfcmsprod/images/Polar_bear_on_ice_in_Svalbard_Norway_WW294883/story_full_width/42ny6cwj8t_Polar_bear_on_ice_in_Svalbard_Norway_WW294883.jpg -O \"polar_bear.jpg\"\n",
        "!wget https://files.worldwildlife.org/wwfcmsprod/images/Asian_Elephants_WW252891/carousel_small/6alkr00kmx_Asian_Elephants_WW252891.jpg -O \"Elephants.jpg\"\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SygZ9YjgAdsL",
        "outputId": "e5f0c0bf-245f-47c0-d57e-46ba0738c3ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-28 15:12:42--  https://learnopencv.com/wp-content/uploads/2020/06/turkish_coffee.jpg\n",
            "Resolving learnopencv.com (learnopencv.com)... 172.66.41.41, 172.66.42.215, 2606:4700:3108::ac42:2929, ...\n",
            "Connecting to learnopencv.com (learnopencv.com)|172.66.41.41|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33843 (33K) [image/jpeg]\n",
            "Saving to: ‘turkish_coffee.jpg’\n",
            "\n",
            "\rturkish_coffee.jpg    0%[                    ]       0  --.-KB/s               \rturkish_coffee.jpg  100%[===================>]  33.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-28 15:12:42 (115 MB/s) - ‘turkish_coffee.jpg’ saved [33843/33843]\n",
            "\n",
            "--2022-08-28 15:12:42--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-28 15:12:42 (80.6 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import tensorrt as trt\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "import torch"
      ],
      "metadata": {
        "id": "dYRXLSZa9y3L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuFR2Esg-h0a",
        "outputId": "d2e2ac35-5987-4764-97ca-e340375a0c1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(1, 3, 224, 224).cuda()\n",
        "model.eval()\n",
        "model.cuda()\n",
        "output = model(input)"
      ],
      "metadata": {
        "id": "rjeRI1XU_Jn1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ONNX_FILE_PATH = 'resnet50.onnx'\n",
        "torch.onnx.export(model, input, ONNX_FILE_PATH, input_names=['input'],\n",
        "                  output_names=['output'], export_params=True)"
      ],
      "metadata": {
        "id": "MTvGzzh8AxYX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"imagenet_classes.txt\") as f:\n",
        "        labels = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "OJwCi2IzJT30"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import tensorrt as trt\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "\n",
        "# logger to capture errors, warnings, and other information during the build and inference phases\n",
        "TRT_LOGGER = trt.Logger()\n",
        "\n",
        "onnx_model = onnx.load(\"resnet50.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "id": "WHb9Ncj_DsGO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_engine_onnx(model_file):\n",
        "    builder = trt.Builder(TRT_LOGGER)\n",
        "    network = builder.create_network(1)\n",
        "    config = builder.create_builder_config()\n",
        "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "\n",
        "    config.max_workspace_size =  1 << 30\n",
        "    # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "    with open(model_file, \"rb\") as model:\n",
        "        if not parser.parse(model.read()):\n",
        "            print(\"ERROR: Failed to parse the ONNX file.\")\n",
        "            for error in range(parser.num_errors):\n",
        "                print(parser.get_error(error))\n",
        "            return None\n",
        "    return builder.build_engine(network, config)"
      ],
      "metadata": {
        "id": "McJmtUTYDyae"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple helper data class that's a little nicer to use than a 2-tuple.\n",
        "class HostDeviceMem(object):\n",
        "    def __init__(self, host_mem, device_mem):\n",
        "        self.host = host_mem\n",
        "        self.device = device_mem\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()"
      ],
      "metadata": {
        "id": "10KtEROIGmal"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\n",
        "def allocate_buffers(engine):\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    bindings = []\n",
        "    stream = cuda.Stream()\n",
        "    for binding in engine:\n",
        "        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
        "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
        "        # Allocate host and device buffers\n",
        "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
        "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
        "        # Append the device buffer to device bindings.\n",
        "        bindings.append(int(device_mem))\n",
        "        # Append to the appropriate list.\n",
        "        if engine.binding_is_input(binding):\n",
        "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "        else:\n",
        "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
        "    return inputs, outputs, bindings, stream"
      ],
      "metadata": {
        "id": "OyAfeijlGHP8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelData(object):\n",
        "    INPUT_SHAPE = (3, 224, 224)\n",
        "    # We can convert TensorRT data types to numpy types with trt.nptype()\n",
        "    DTYPE = trt.float32"
      ],
      "metadata": {
        "id": "3-1OIPfxLeiB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_normalized_test_case(test_image, pagelocked_buffer):\n",
        "    # Converts the input image to a CHW Numpy array\n",
        "    def normalize_image(image):\n",
        "        # Resize, antialias and transpose the image to CHW.\n",
        "        c, h, w = ModelData.INPUT_SHAPE\n",
        "        image_arr = (\n",
        "            np.asarray(image.resize((w, h), Image.ANTIALIAS))\n",
        "            .transpose([2, 0, 1])\n",
        "            .astype(trt.nptype(ModelData.DTYPE))\n",
        "            .ravel()\n",
        "        )\n",
        "        # This particular ResNet50 model requires some preprocessing, specifically, mean normalization.\n",
        "        return (image_arr / 255.0 - 0.45) / 0.225\n",
        "\n",
        "    # Normalize the image and copy to pagelocked memory.\n",
        "    np.copyto(pagelocked_buffer, normalize_image(Image.open(test_image)))\n",
        "    return test_image"
      ],
      "metadata": {
        "id": "ge7xMgQBG9Ml"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_inference_v2(context, bindings, inputs, outputs, stream):\n",
        "    # Transfer input data to the GPU.\n",
        "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
        "    # Run inference.\n",
        "    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
        "    # Transfer predictions back from the GPU.\n",
        "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
        "    # Synchronize the stream\n",
        "    stream.synchronize()\n",
        "    # Return only the host outputs.\n",
        "    return [out.host for out in outputs]"
      ],
      "metadata": {
        "id": "I8D3qMlVJDp0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a TensorRT engine.\n",
        "engine = build_engine_onnx(\"resnet50.onnx\")\n",
        "# Inference is the same regardless of which parser is used to build the engine, since the model architecture is the same.\n",
        "# Allocate buffers and create a CUDA stream.\n",
        "inputs, outputs, bindings, stream = allocate_buffers(engine)\n",
        "# Contexts are used to perform inference.\n",
        "context = engine.create_execution_context()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdCvgW-sD_r-",
        "outputId": "298b42dc-85e4-484e-f8ec-ac426d9904e6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Use set_memory_pool_limit instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Use build_serialized_network instead.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Use network created with NetworkDefinitionCreationFlag::EXPLICIT_BATCH flag instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=1)"
      ],
      "metadata": {
        "id": "e8XLvGwsNYEV"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(image_path):\n",
        "  test_case = load_normalized_test_case(image_path, inputs[0].host)\n",
        "  trt_outputs = softmax(do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream))\n",
        "  pred = labels[np.argmax(trt_outputs[0])]\n",
        "  proba = trt_outputs[0][np.argmax(trt_outputs[0])]*100\n",
        "  return(pred,proba)"
      ],
      "metadata": {
        "id": "9uwI-VJLJ-dI"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/content/turkish_coffee.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1lm5C_BP7tv",
        "outputId": "ff6ec50c-29b9-44a5-c79c-fe58e12c903f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('espresso', 64.87869024276733)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/content/polar_bear.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA_TeP-gQCSs",
        "outputId": "551d1e6c-fb79-421d-c4cc-1b53cb0f96b5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ice bear', 99.99052882194519)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aag37YPTQAPd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}